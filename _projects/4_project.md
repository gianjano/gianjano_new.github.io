---
layout: page
title: Ecomode
description: Event-Driven compressive vision for multimodal interaction with mobile devices
img: assets/img/ecomode.jpg
importance: 3
category: past
---

    Coordinator: Sorbonne Universite ğŸ‡«ğŸ‡·
    Partners: FBK ğŸ‡®ğŸ‡¹, Streetlab ğŸ‡«ğŸ‡·, Experis ğŸ‡ªğŸ‡¸, IIT ğŸ‡®ğŸ‡¹, Prophesee ğŸ‡«ğŸ‡·, Innovati ğŸ‡ªğŸ‡¸, Spanish National Research Cpuncil ğŸ‡ªğŸ‡¸  and Insitute de la Vision ğŸ‡«ğŸ‡·

ECOMODE was a research project funded under Horizon 2020, in which we developed an innovative technology that allows visually impaired people and older adults to interact with mobile technology using mid-air gestures and voice controls. 
ECOMODE technology integrates a neuromorphic camera inspired by human vision, making it possible to control smartphones and tablet devices with multimodal interaction, regardless of environmental conditions and background noise.

<iframe width="790" height="444" src="https://www.youtube.com/embed/R_ePduzmQ9s" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>   

